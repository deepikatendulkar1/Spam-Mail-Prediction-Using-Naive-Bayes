{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMABaEbV6dhGzpUXa7C13WD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_uNii7oYfSAe","executionInfo":{"status":"ok","timestamp":1731278476005,"user_tz":300,"elapsed":1001,"user":{"displayName":"Deepika Tendulkar","userId":"10504795624445086968"}},"outputId":"78805262-d2d6-4841-dcaa-7ac0877a3e7b"},"outputs":[{"output_type":"stream","name":"stdout","text":[" 0       0\n","1       0\n","2       0\n","3       1\n","4       0\n","       ..\n","5166    0\n","5167    0\n","5168    0\n","5169    0\n","5170    1\n","Name: label_num, Length: 5171, dtype: int64\n"," 1023    Subject: re : tenaska\\r\\ni see the demand fee ...\n","4586    Subject: strong buy alert : monthly newsletter...\n","2955    Subject: performance feedback\\r\\neach of you h...\n","2495    Subject: hr performance objectives binders\\r\\n...\n","3353    Subject: fw : [ fwd : fw : drawing by a school...\n","                              ...                        \n","4426    Subject: re : ena sales on hpl\\r\\nlast that i ...\n","466     Subject: tenaska iv\\r\\nbob :\\r\\ni understand f...\n","3092    Subject: broom , bristles up , flew\\r\\nbe diff...\n","3772    Subject: calpine daily gas nomination ( weeken...\n","860     Subject: re : meter 1459 , 6 / 00\\r\\nyep , you...\n","Name: text, Length: 3619, dtype: object\n"," 1566    0\n","1988    1\n","1235    0\n","2868    0\n","4903    0\n","       ..\n","5135    0\n","2298    0\n","1519    0\n","1740    1\n","1700    0\n","Name: label_num, Length: 1552, dtype: int64\n","X_train_vec   (0, 152)\t1\n","  (0, 156)\t1\n","  (0, 168)\t4\n","  (0, 34)\t2\n","  (0, 149)\t2\n","  (0, 52)\t2\n","  (0, 167)\t1\n","  (0, 30)\t1\n","  (0, 47)\t1\n","  (0, 90)\t2\n","  (0, 194)\t1\n","  (0, 79)\t3\n","  (0, 11)\t1\n","  (0, 0)\t2\n","  (0, 13)\t1\n","  (0, 187)\t2\n","  (0, 133)\t1\n","  (0, 63)\t1\n","  (0, 37)\t1\n","  (0, 178)\t1\n","  (1, 168)\t65\n","  (1, 34)\t33\n","  (1, 149)\t1\n","  (1, 167)\t8\n","  (1, 30)\t6\n","  :\t:\n","  (3618, 190)\t1\n","  (3618, 198)\t2\n","  (3618, 117)\t2\n","  (3618, 17)\t1\n","  (3618, 125)\t1\n","  (3618, 86)\t2\n","  (3618, 98)\t1\n","  (3618, 147)\t2\n","  (3618, 108)\t3\n","  (3618, 166)\t1\n","  (3618, 14)\t1\n","  (3618, 19)\t2\n","  (3618, 91)\t1\n","  (3618, 60)\t3\n","  (3618, 73)\t2\n","  (3618, 2)\t1\n","  (3618, 94)\t2\n","  (3618, 67)\t4\n","  (3618, 51)\t2\n","  (3618, 61)\t1\n","  (3618, 109)\t3\n","  (3618, 119)\t4\n","  (3618, 70)\t1\n","  (3618, 8)\t2\n","  (3618, 3)\t1\n","X_test_vec   (0, 20)\t1\n","  (0, 25)\t1\n","  (0, 40)\t1\n","  (0, 74)\t1\n","  (0, 79)\t1\n","  (0, 96)\t1\n","  (0, 114)\t1\n","  (0, 128)\t1\n","  (0, 156)\t1\n","  (0, 197)\t2\n","  (1, 30)\t3\n","  (1, 39)\t1\n","  (1, 131)\t1\n","  (1, 168)\t1\n","  (1, 179)\t1\n","  (1, 199)\t2\n","  (2, 1)\t1\n","  (2, 5)\t1\n","  (2, 11)\t1\n","  (2, 20)\t1\n","  (2, 32)\t1\n","  (2, 36)\t2\n","  (2, 51)\t1\n","  (2, 53)\t2\n","  (2, 72)\t2\n","  :\t:\n","  (1551, 119)\t1\n","  (1551, 120)\t1\n","  (1551, 121)\t2\n","  (1551, 133)\t2\n","  (1551, 134)\t2\n","  (1551, 135)\t1\n","  (1551, 137)\t1\n","  (1551, 141)\t1\n","  (1551, 142)\t1\n","  (1551, 147)\t2\n","  (1551, 148)\t1\n","  (1551, 149)\t1\n","  (1551, 151)\t1\n","  (1551, 159)\t1\n","  (1551, 166)\t1\n","  (1551, 167)\t1\n","  (1551, 168)\t7\n","  (1551, 171)\t1\n","  (1551, 174)\t2\n","  (1551, 176)\t3\n","  (1551, 177)\t1\n","  (1551, 178)\t1\n","  (1551, 183)\t1\n","  (1551, 187)\t1\n","  (1551, 193)\t2\n","Accuracy: 0.8923969072164949\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.95      0.89      0.92      1121\n","           1       0.76      0.89      0.82       431\n","\n","    accuracy                           0.89      1552\n","   macro avg       0.86      0.89      0.87      1552\n","weighted avg       0.90      0.89      0.89      1552\n","\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# Load data (assuming the file is saved as 'spam_data.csv' after extracting text from the image)\n","data = pd.read_csv('/content/sample_data/spam.csv')\n","\n","# Make sure columns are properly named\n","data.columns = ['index', 'label', 'text', 'label_num']\n","\n","# Encode labels if not already numeric\n","if data['label_num'].dtype != 'int':\n","    data['label_num'] = data['label'].map({'ham': 0, 'spam': 1})\n","print(\"\", data['label_num'])\n","# Split data\n","X_train, X_test, y_train, y_test = train_test_split(data['text'], data['label_num'], test_size=0.3, random_state=42)\n","print(\"\",X_train)\n","print(\"\",y_test)\n","# Vectorize text data\n","vectorizer = CountVectorizer(max_features=200, min_df=2, max_df=0.8)\n","X_train_vec = vectorizer.fit_transform(X_train)\n","X_test_vec = vectorizer.transform(X_test)\n","print(\"X_train_vec\",X_train_vec)\n","print(\"X_test_vec\",X_test_vec)\n","# Train model\n","model = MultinomialNB()\n","model.fit(X_train_vec, y_train)\n","\n","# Predict\n","y_pred = model.predict(X_test_vec)\n","\n","# Evaluate model\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"]},{"cell_type":"code","source":[],"metadata":{"id":"5Uu6agLqrwWE"},"execution_count":null,"outputs":[]}]}